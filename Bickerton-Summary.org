
Bickerton, D. (1991). Language & species. Chicago, IL: Univ. of Chicago Press

Derek Bickerton examines langauge as the heart of human competitive advantage in his book Language and Species. Other authors explore how humans gained advantage through consciousness and power over nature.  But Bickerton claims our use of language is most important and perhaps primary. It is difficult to reflect upon language as we do our other capacities, so we are still in the infancy of learning the power of language. This includes its affordances for our mental abilities.

Bickerton first approaches what he calls the "Continuity Paradox."  Problems arise when we try to examine language as an artifact of natural selection. If language evolved, then it must have evolved from something. But, the communication systems of other animals pale in comparison to those of humans. From bees to chimps to dolphins, animals have adapted forms of communications. Yet studies of each suggest that communications are holistic and not generative. This difference is fundamental and qualitative. Holistic language creates meaning only in utterances rather than lexical or grammatical constructions. So, animals can say "Look out, a snake!" or "Look  out, an eagle", but they can't simply say "a snake" or "an eagle". This means they are unable to reuse parts of their language in generative ways to form new meanings.

Humans are able to reuse and re-contextualize language parts to form new meanings. So we can move from "Look out, a snake!" to "Look, a snake" to "A snake looks". By separating an utterance into reusable parts, humans can form infinite meanings. This is qualitatively different from the animal utterances. A holistic language is bound by environment, perceptions, and immediate concepts.

Bickerton posits changes in representation brought on lexical and grammatical language. By focusing on representation, Bickerton side-steps the continuity paradox of communication systems. Communication systems presuppose meaning as use and are inherently social. Representation, in contrast, is personal, but still universal. Formal studies of language have illuminated the underlying structure of language. The formal structures are the underpinnings that allow use as a communication system. So, the roots of language are actually representational, rather than communicative. Humans developed systems for representing entities and things predicated on entities. We use these systems for communication.

Humans categorize things in the world, and describe their attributes and what they do. These categories form the bulk of lexical items of language. and grammatical structures form much of the rest. The lexicon is "things in the world" and the grammar is "how to relate them with language". Syntactic structures work on ontological systems to make sense of the world. Bickerton thinks this jump is what sets humans apart from other animals. The move from animal representation to human representation is much smaller than animal communication to human communication. Animals can also represent categories in their own communication systems. But, humans have codified representations into grammatical structures. The space between representation and utterance is grammar. Grammar allows generative language.

But how does representation link to language? After the introductory chapter, Bickerton bridges the gap. He explores animal representational systems. He looks at how we carve up semantic space. And, he shows that our hierarchical semantic space lends itself to predicability.

The author starts with a metaphor of language as both map and itinerary for representation. It is a map in the way it abstracts concepts from actual things. In this metaphor, we have concepts in our mental map, but concepts hide details of actual entities. Bickerton gives the example of a painting of a battle, where the battle may be recognizable, but its medium, scent, sounds, and third dimension are all missing. Still, we recognize the same battle in person or painting.

Of course, mapping reality onto concepts is something animals can also do. Animals can sound alarms without seeing entire animals, but only hints or pieces. This means that they must have some concept of e.g. /leopard/ without needing an entire leopard present. Further, animals merge sight, sound, and scent onto a single entity for their reaction. 

Humans do similar mapping to concrete entities like leopards. We are also able to create abstractions like /burglar/, /paranoia/, or /unicorn/. /Burglar/ and /paranoia/  rely on other social concepts like property and ownership or mental state and persecution. /Unicorn/ requires whole-cloth imagination for a concept without incorporation.

We derive many words and concepts from functional distinctions. Bickerton gives the example of trees and bushes. The physical properties that separate the two concepts are very blurry. Some trees are short or have many branches. Some bushes are tall or only have a few branches. But, in general trees can be climbed, or can grow big enough to do so. Bushes, on the other hand, can be used for hiding if well grown. 

"Burglar" performs a social function in identifying people who burgle. "Paranoia" labels people with certain mental states. Even unicorns also have social function in storytelling and mythology.

Of course, the language structure and conceptual maps aren't without their limiting guidelines. Linguistics studies of the past few decades have shown that semantic maps are far from arbitrary. For example, existence, location, possession and ownership map onto the English verbs "to be" or "to have". Other languages divvy up these concepts differently, but some combinations never occur. These types of regularities are pervasive when examining languages throughout the world.

Bickerton explores the itinerary side of his metaphor for language in Chapter 3. The mapping of language takes entities and represents them with concepts. The itinerary of language describes the structure of language for relating concepts together. The structure of language resides in predicability, grammatization, and syntax.

Predicability is the way that we use language descriptively. It allows us to make categorical statements, like "a dog is a mammal", ", descriptive statements, like "the grass is green", and metaphorical statements, like "money is the root of all evil". Predicability also constrains language, in the categories it imposes. So, while "the grass is green" makes sense, "the idea is green" does not. So, language employs predicability to categorize objects and actions by function. We can then exploit these categories to highlight relationships through metaphor. In this way, evil can have roots, or familiarity can breed (contempt).

Grammatization inserts information into language when it seems like it could be optional. Willard Quine was famously perplexed at the necessity of tense in expression. It is one example of information necessary to make grammatical sentences in English. We cannot avoid marking tense, and speakers of other languages cannot avoid marking gender or epistemics.

Grammatical markers may also take optional forms.  For example, prepositions make different distinctions in different languages. Modal markers in English are always optional, but other languages use them in their morphology as standard markers. Directional markers can also vary by language and grammaticity. English often uses egocentric references like left and right. Other languages may use local geography like uphill and downhill.

An interesting component of grammaticized language is its functional orientation. Grammatical structure shows signs of functionalism in it orientation to relative comparison. For example, most prepositional phrases are relative. For example, "next to the fridge" and "next to the mountain" are much different areas of precision. Each depends on the size of the referent rather than the "next to the" grammatical phrasing.

The final aspect of language structure is syntax. Predicability and grammar inform syntax, of course. Some sentences have poor syntax due to predicate violations (e.g. ideas can't sleep). Some have grammar violations (e.g. something can be "on the left" but not "under the left"). But syntax also includes word order, phrase order, phrase structure, and more. "The left to" or "sleep ideas" are meaningless in due to word order rather than predication or grammatization. Expanding from phrases, "Sue left Tom" has a different meaning than "Tom left Sue", even with the same words. Different language bend word or phrase order in different ways. But, syntactic forms for distinctions like these have shown up in all studied languages. So, there is a deeper level of organization in language universally informing linguistic thought. 

The itinerary aspects of language allow humans endless expressive power. Syntactic combinatorics moves us past the holism of animal calls. We can use finite number of words to express an infinite number of thoughts. The similarities of the world's languages illuminate the core power of syntax. So, language uses syntax to guide semantic relations. Grammar gives language its combinatoric power to move from the holism of animals to the expressive power of humans. Our syntactic itinerary combines with our representational map giving us language. These unique properties of language give us an unparalleled communicative system. 
