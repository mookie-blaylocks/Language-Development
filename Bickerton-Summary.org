
Bickerton, D. (1991). Language & species. Chicago, IL: Univ. of Chicago Press

Derek Bickerton examines langauge as the heart of human competitive advantage in his book Language and Species. Other authors explore how humans gained advantage through consciousness and power over nature.  But Bickerton claims our use of language is most important and perhaps primary. It is difficult to reflect upon language as we do our other capacities, so we are still in the infancy of learning the power of language. This includes its affordances for our mental abilities.

Bickerton first approaches what he calls the "Continuity Paradox."  Problems arise when we try to examine language as an artifact of natural selection. If language evolved, then it must have evolved from something. But, the communication systems of other animals pale in comparison to those of humans. From bees to chimps to dolphins, animals have adapted forms of communications. Yet studies of each suggest that communications are holistic and not generative. This difference is fundamental and qualitative. Holistic language creates meaning only in utterances rather than lexical or grammatical constructions. So, animals can say "Look out, a snake!" or "Look  out, an eagle", but they can't simply say "a snake" or "an eagle". This means they are unable to reuse parts of their language in generative ways to form new meanings.

Humans are able to reuse and re-contextualize language parts to form new meanings. So we can move from "Look out, a snake!" to "Look, a snake" to "A snake looks". By separating an utterance into reusable parts, humans can form infinite meanings. This is qualitatively different from the animal utterances. A holistic language is bound by environment, perceptions, and immediate concepts.

Bickerton posits changes in representation brought on lexical and grammatical language. By focusing on representation, Bickerton side-steps the continuity paradox of communication systems. Communication systems presuppose meaning as use and are inherently social. Representation, in contrast, is personal, but still universal. Formal studies of language have illuminated the underlying structure of language. The formal structures are the underpinnings that allow use as a communication system. So, the roots of language are actually representational, rather than communicative. Humans developed systems for representing entities and things predicated on entities. We use these systems for communication.

Humans categorize things in the world, and describe their attributes and what they do. These categories form the bulk of lexical items of language. and grammatical structures form much of the rest. The lexicon is "things in the world" and the grammar is "how to relate them with language". Syntactic structures work on ontological systems to make sense of the world. Bickerton thinks this jump is what sets humans apart from other animals. The move from animal representation to human representation is much smaller than animal communication to human communication. Animals can also represent categories in their own communication systems. But, humans have codified representations into grammatical structures. The space between representation and utterance is grammar. Grammar allows generative language.

But how does representation link to language? After the introductory chapter, Bickerton bridges the gap. He explores animal representational systems. He looks at how we carve up semantic space. And, he shows that our hierarchical semantic space lends itself to predicability.

The author starts with a metaphor of language as both map and itinerary for representation. It is a map in the way it abstracts concepts from actual things. In this metaphor, we have concepts in our mental map, but concepts hide details of actual entities. Bickerton gives the example of a painting of a battle, where the battle may be recognizable, but its medium, scent, sounds, and third dimension are all missing. Still, we recognize the same battle in person or painting.

Of course, mapping reality onto concepts is something animals can also do. Animals can sound alarms without seeing entire animals, but only hints or pieces. This means that they must have some concept of e.g. /leopard/ without needing an entire leopard present. Further, animals merge sight, sound, and scent onto a single entity for their reaction. 

Humans do similar mapping to concrete entities like leopards. We are also able to create abstractions like /burglar/, /paranoia/, or /unicorn/. /Burglar/ and /paranoia/  rely on other social concepts like property and ownership or mental state and persecution. /Unicorn/ requires whole-cloth imagination for a concept without incorporation.

We derive many words and concepts from functional distinctions. Bickerton gives the example of trees and bushes. The physical properties that separate the two concepts are very blurry. Some trees are short or have many branches. Some bushes are tall or only have a few branches. But, in general trees can be climbed, or can grow big enough to do so. Bushes, on the other hand, can be used for hiding if well grown. 

"Burglar" performs a social function in identifying people who burgle. "Paranoia" labels people with certain mental states. Even unicorns also have social function in storytelling and mythology.

Of course, the language structure and conceptual maps aren't without their limitations and guidelines. Linguistics studies of the past few decades have shown that semantic maps are far from arbitrary. For example, existence, location, possession and ownership map onto the English verbs "to be" or "to have". Other languages divvy up these concepts differently, but some combinations never occur. These types of regularities are pervasive when examining languages throughout the world.

Continuing with the map and itinerary metaphor, Bickerton explores the itinerary side of language in Chapter 3. Beyond referring with nouns and verbs, language also describes these references and also gives expression structure. The structure of language boils down to three main points: predicability, grammatization, and syntax.

Predicability is the way that we use language descriptively. It allows us to make categorical statements, like "a dog is a mammal", ", descriptive statements, like "the grass is green", and metaphorical statements, like "money is the root of all evil. Predicability also constrains language, in the categories it imposes. So, while "the grass is green" makes sense, "the idea is green" does not. So, language employs predicability to functionally categorize objects and actions. We can then exploit these categories to highlight relationships through metaphor. In this way, evil can have roots, or familiarity can breed (contempt).

Grammatization inserts information into language when it seems like it coule be optional. Bickerton cites Willard Quine specifically being perplexed at the necessity of tense in expression. It is just one example of information that must be included in English to make grammatical sentences. We cannot avoid marking tense, just as speakers of other language cannot avoid marking gender, agency or epistemics. Of course, these distinctions aren't always obligatory in the way that tense is, but some still find their way into language through prepositions (above, below, in), modal markers (usually, possibly, necessarily), or direction (to, up, left). 

An interesting component of grammaticized language is its functional orientation. Like Bickerton's story of lexical items forming through function, grammatical also shows signs of functionalism in the way that it orients itself to relative comparison. For example, most prepositional phrases are relative. For example, "next to the fridge" and "next to the mountain" are much different areas of precision, each relative to the size of the referent rather than the "next to the" grammatical phrasing.

Finally, Bickerton considers syntax and the structure of phrases and sentences. Predicability and grammar inform syntax, of course. There are sentences that don't parse syntactically because of predicate violations (e.g. ideas can't sleep) or grammar violations (e.g. something can be "on the left" but not "under the left"). But these are only aspects of syntax, which also includes word order, phrase order, phrase structure, and more. "The left to" or "sleep ideas" are meaningless in different ways than the previous violations since their word order does not follow convention. Expanding from phrases, "Sue left Tom" has a different meaning than "Tom left Sue", even with the same words. These syntactic forms are pervasive in English and have shown up in all languages that have been studied. This suggests that there is a deeper level of organization in language that universally informs linguistic thought. 

Further, the so called "universal grammar" gives language it's combinatoric power where the lexicon can employ a standard structure in order to express endless thoughts with finite words. Humans can count on the structure to inform the parsing and provide an itenerary through the lexical ideas found in phrases or sentences.
